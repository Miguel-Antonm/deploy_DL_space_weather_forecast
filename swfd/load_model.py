# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/02_load_model.ipynb (unless otherwise specified).

__all__ = ['loadModel', 'getCsvData', 'getNameRunFolders', 'singlePrediction', 'ensemblePrediction', 'ensembleMeanVar',
           'modelPrediction']

# Cell
import torch
import yaml
from fastcore.script import *
from .recursos.model import *
import csv
import numpy as np
import os
import matplotlib.pyplot as plt
from .web_scraping import *

# Cell
def loadModel(pathrun):
    pathyaml=str(pathrun)+"config.yaml"
    pathpth=str(pathrun)+"best.pth"
    config=yaml.safe_load(open(str(pathyaml)))
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = NBeatsNet(device=device,stack_types=(NBeatsNet.GENERIC_BLOCK, NBeatsNet.GENERIC_BLOCK),
                  nb_blocks_per_stack=config["nb_blocks_per_stack"]["value"],
                  thetas_dims=config["thetas_dims"]["value"],
                  hidden_layer_units=config["hidden_layer_units"]["value"],
                  forecast_length=config["horizon"]["value"],backcast_length=config["lookback"]["value"])
    checkpoint = torch.load(pathpth,map_location=device)
    model.load_state_dict(checkpoint['model_state_dict'])
    model.eval()
    return model


# Cell
def getCsvData(lookback,start=0 ): #Inicio=start
    pathfoldercsv=getInfo("csvdirectory") #Obtiene del txt el path del csv
    csvname="sfuData.csv" #Siempre se llamara as√≠
    #csvname="2020.csv" #Ejemplocsv de datos de  2019-2020
    datalist=[]
    try:
        with open(str(pathfoldercsv)+str(csvname)) as csv_file:
            forecastcount=0
            startcount=1
            for row in reversed(list(csv.reader(csv_file, delimiter=','))):
                if startcount < start:
                    startcount= startcount +1
                elif(forecastcount<lookback):
                    datalist=np.append(datalist,float(row[1]))
                    forecastcount=forecastcount+1


    finally:
        csv_file.close()
    return datalist


# Cell
def getNameRunFolders(horizon,runshorizonfolder):
    runshorizonfolder=runshorizonfolder+"ensembleH"+str(horizon)
    pathfolderruns=[] #runs_directories
    contenido = os.listdir(str(runshorizonfolder))
    for i in contenido:
        pathrun=runshorizonfolder+"/"+str(i)+"/"
        pathfolderruns.append(pathrun)

    return pathfolderruns


# Cell
def singlePrediction(filepath,normalize):
    net=loadModel(str(filepath))
    lookback=net.backcast_length
    data=getCsvData(lookback)#,net.forecast_length)
    row = torch.Tensor([data/normalize])
    backcast,forecast = net(row)
    preds_tensor=(forecast.detach().numpy())*normalize
    return preds_tensor[0].reshape(1,net.forecast_length)


# Cell
def ensemblePrediction(horizon,normalize):
    prediction=np.empty((0,horizon))
    #prediction=np.matrix(np.empty(shape=(prediction,horizon), dtype=float))
    folderpath=getInfo("pthdirectory")
    runspath=getNameRunFolders(horizon,folderpath)
    for run in runspath:
        prediction=np.append(prediction,singlePrediction(run,normalize),axis=0)
    return prediction

# Cell
def ensembleMeanVar(prediction):
    meanlist=[]
    stdlist=[]
    for row in prediction.T:
        meanlist.append(row.mean())
        stdlist.append(row.std())

    return np.array(meanlist),np.array(stdlist)

# Cell
def modelPrediction(forecast,normal):#Parametro normal esta para hacer pruebas
    #normalize=getMaxValueSfu()
    normalize=normal#Funcion web_scraping getMaxValueSfu(), funciona, pero parra ahorrar tiempo en las pruebas

    prediction=ensemblePrediction(forecast,normalize)

    mean,std=ensembleMeanVar(prediction)
    return prediction,mean,std
