{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import os\n",
    "import re\n",
    "\n",
    "#N-BEATS\n",
    "import pickle\n",
    "import random\n",
    "from time import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.nn.functional import mse_loss, l1_loss, binary_cross_entropy, cross_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "back(): Devuelve el path de la carpeta anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def back():\n",
    "    path=os.getcwd()\n",
    "    s=path.split('/')\n",
    "    length=len(s)\n",
    "    back_path=\"\"\n",
    "    for pathpart in range(0,length-1):\n",
    "        if pathpart==0:\n",
    "            back_path=s[pathpart]+\"/\"\n",
    "        else:\n",
    "            back_path=back_path+s[pathpart]+\"/\"\n",
    "    return str(back_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deploy_DL_space_weather_forecast\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "print(back().split(\"/\")[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def getInfo(element):\n",
    "    try:\n",
    "        txtpath=str(back())+\"infouser.txt\"\n",
    "        if os.path.isfile(txtpath):\n",
    "            f = open (txtpath,'r')\n",
    "            message = f.read()\n",
    "            info=re.findall(str(element)+\"='(.*?)'\",message)\n",
    "        else:\n",
    "            txtpath=str(back())+\"test/infotest.txt\"\n",
    "            f = open (txtpath,'r')\n",
    "            message = f.read()\n",
    "            info=re.findall(str(element)+\"='(.*?)'\",message)\n",
    "        if(len(info)>0):\n",
    "            info=info[0] #En caso de repetidos se devuelve el primero\n",
    "    finally:\n",
    "        f.close()\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is a test\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "print(getInfo(\"test\"))\n",
    "#If value not exist return []\n",
    "print(getInfo(\"holidays\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "@misc{NBeatsPRemy,\n",
    "  author = {Philippe Remy},\n",
    "  title = {N-BEATS: Neural basis expansion analysis for interpretable time series forecasting},\n",
    "  year = {2020},\n",
    "  publisher = {GitHub},\n",
    "  journal = {GitHub repository},\n",
    "  howpublished = {\\url{https://github.com/philipperemy/n-beats}},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class NBeatsNet(nn.Module):\n",
    "    SEASONALITY_BLOCK = 'seasonality'\n",
    "    TREND_BLOCK = 'trend'\n",
    "    GENERIC_BLOCK = 'generic'\n",
    "\n",
    "    def __init__(self,\n",
    "                 device=torch.device('cpu'),\n",
    "                 stack_types=(TREND_BLOCK, SEASONALITY_BLOCK),\n",
    "                 nb_blocks_per_stack=3,\n",
    "                 forecast_length=5,\n",
    "                 backcast_length=10,\n",
    "                 thetas_dim=(4, 8),\n",
    "                 share_weights_in_stack=False,\n",
    "                 hidden_layer_units=256,\n",
    "                 nb_harmonics=None):\n",
    "        super(NBeatsNet, self).__init__()\n",
    "        self.forecast_length = forecast_length\n",
    "        self.backcast_length = backcast_length\n",
    "        self.hidden_layer_units = hidden_layer_units\n",
    "        self.nb_blocks_per_stack = nb_blocks_per_stack\n",
    "        self.share_weights_in_stack = share_weights_in_stack\n",
    "        self.nb_harmonics = nb_harmonics\n",
    "        self.stack_types = stack_types\n",
    "        self.stacks = []\n",
    "        self.thetas_dim = thetas_dim\n",
    "        self.parameters = []\n",
    "        self.device = device\n",
    "        #print('| N-Beats')\n",
    "        for stack_id in range(len(self.stack_types)):\n",
    "            self.stacks.append(self.create_stack(stack_id))\n",
    "        self.parameters = nn.ParameterList(self.parameters)\n",
    "        self.to(self.device)\n",
    "        self._loss = None\n",
    "        self._opt = None\n",
    "\n",
    "    def create_stack(self, stack_id):\n",
    "        stack_type = self.stack_types[stack_id]\n",
    "        #print(f'| --  Stack {stack_type.title()} (#{stack_id}) (share_weights_in_stack={self.share_weights_in_stack})')\n",
    "        blocks = []\n",
    "        for block_id in range(self.nb_blocks_per_stack):\n",
    "            block_init = NBeatsNet.select_block(stack_type)\n",
    "            if self.share_weights_in_stack and block_id != 0:\n",
    "                block = blocks[-1]  # pick up the last one when we share weights.\n",
    "            else:\n",
    "                block = block_init(self.hidden_layer_units, self.thetas_dim[stack_id],\n",
    "                                   self.device, self.backcast_length, self.forecast_length, self.nb_harmonics)\n",
    "                self.parameters.extend(block.parameters())\n",
    "            #print(f'     | -- {block}')\n",
    "            blocks.append(block)\n",
    "        return blocks\n",
    "\n",
    "    def save(self, filename: str):\n",
    "        torch.save(self, filename)\n",
    "\n",
    "    @staticmethod\n",
    "    def load(f, map_location=None, pickle_module=pickle, **pickle_load_args):\n",
    "        return torch.load(f, map_location, pickle_module, **pickle_load_args)\n",
    "\n",
    "    @staticmethod\n",
    "    def select_block(block_type):\n",
    "        if block_type == NBeatsNet.SEASONALITY_BLOCK:\n",
    "            return SeasonalityBlock\n",
    "        elif block_type == NBeatsNet.TREND_BLOCK:\n",
    "            return TrendBlock\n",
    "        else:\n",
    "            return GenericBlock\n",
    "\n",
    "    def compile_model(self, loss: str, learning_rate: float):\n",
    "        # TODO: check that.\n",
    "        if loss == 'mae':\n",
    "            loss_ = l1_loss\n",
    "        elif loss == 'mse':\n",
    "            loss_ = mse_loss\n",
    "        elif loss == 'cross_entropy':\n",
    "            loss_ = cross_entropy\n",
    "        elif loss == 'binary_crossentropy':\n",
    "            loss_ = binary_cross_entropy\n",
    "        else:\n",
    "            raise ValueError(f'Unknown loss name: {loss}.')\n",
    "        # noinspection PyArgumentList\n",
    "        self._opt = optim.Adam(lr=learning_rate, params=self.parameters())\n",
    "        self._loss = loss_\n",
    "\n",
    "    def fit(self, x_train, y_train, validation_data=None, epochs=10, batch_size=32):\n",
    "\n",
    "        def split(arr, size):\n",
    "            arrays = []\n",
    "            while len(arr) > size:\n",
    "                slice_ = arr[:size]\n",
    "                arrays.append(slice_)\n",
    "                arr = arr[size:]\n",
    "            arrays.append(arr)\n",
    "            return arrays\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            x_train_list = split(x_train, batch_size)\n",
    "            y_train_list = split(y_train, batch_size)\n",
    "            assert len(x_train_list) == len(y_train_list)\n",
    "            shuffled_indices = list(range(len(x_train_list)))\n",
    "            random.shuffle(shuffled_indices)\n",
    "            self.train()\n",
    "            train_loss = []\n",
    "            timer = time()\n",
    "            for batch_id in shuffled_indices:\n",
    "                batch_x, batch_y = x_train_list[batch_id], y_train_list[batch_id]\n",
    "                self._opt.zero_grad()\n",
    "                _, forecast = self(torch.tensor(batch_x, dtype=torch.float).to(self.device))\n",
    "                loss = self._loss(forecast, squeeze_last_dim(torch.tensor(batch_y, dtype=torch.float).to(self.device)))\n",
    "                train_loss.append(loss.item())\n",
    "                loss.backward()\n",
    "                self._opt.step()\n",
    "            elapsed_time = time() - timer\n",
    "            train_loss = np.mean(train_loss)\n",
    "\n",
    "            test_loss = '[undefined]'\n",
    "            if validation_data is not None:\n",
    "                x_test, y_test = validation_data\n",
    "                self.eval()\n",
    "                _, forecast = self(torch.tensor(x_test, dtype=torch.float).to(self.device))\n",
    "                test_loss = self._loss(forecast, squeeze_last_dim(torch.tensor(y_test, dtype=torch.float))).item()\n",
    "\n",
    "            num_samples = len(x_train_list)\n",
    "            time_per_step = int(elapsed_time / num_samples * 1000)\n",
    "            print(f'Epoch {str(epoch + 1).zfill(len(str(epochs)))}/{epochs}')\n",
    "            print(f'{num_samples}/{num_samples} [==============================] - '\n",
    "                  f'{int(elapsed_time)}s {time_per_step}ms/step - '\n",
    "                  f'loss: {train_loss:.4f} - val_loss: {test_loss:.4f}')\n",
    "\n",
    "    def predict(self, x, return_backcast=False):\n",
    "        self.eval()\n",
    "        b, f = self(torch.tensor(x, dtype=torch.float).to(self.device))\n",
    "        b, f = b.detach().numpy(), f.detach().numpy()\n",
    "        if len(x.shape) == 3:\n",
    "            b = np.expand_dims(b, axis=-1)\n",
    "            f = np.expand_dims(f, axis=-1)\n",
    "        if return_backcast:\n",
    "            return b, f\n",
    "        return f\n",
    "\n",
    "    def forward(self, backcast):\n",
    "        backcast = squeeze_last_dim(backcast)\n",
    "        forecast = torch.zeros(size=(backcast.size()[0], self.forecast_length,))  # maybe batch size here.\n",
    "        for stack_id in range(len(self.stacks)):\n",
    "            for block_id in range(len(self.stacks[stack_id])):\n",
    "                b, f = self.stacks[stack_id][block_id](backcast)\n",
    "                backcast = backcast.to(self.device) - b\n",
    "                forecast = forecast.to(self.device) + f\n",
    "        return backcast, forecast\n",
    "\n",
    "\n",
    "def squeeze_last_dim(tensor):\n",
    "    if len(tensor.shape) == 3 and tensor.shape[-1] == 1:  # (128, 10, 1) => (128, 10).\n",
    "        return tensor[..., 0]\n",
    "    return tensor\n",
    "\n",
    "\n",
    "def seasonality_model(thetas, t, device):\n",
    "    p = thetas.size()[-1]\n",
    "    assert p <= thetas.shape[1], 'thetas_dim is too big.'\n",
    "    p1, p2 = (p // 2, p // 2) if p % 2 == 0 else (p // 2, p // 2 + 1)\n",
    "    s1 = torch.tensor([np.cos(2 * np.pi * i * t) for i in range(p1)]).float()  # H/2-1\n",
    "    s2 = torch.tensor([np.sin(2 * np.pi * i * t) for i in range(p2)]).float()\n",
    "    S = torch.cat([s1, s2])\n",
    "    return thetas.mm(S.to(device))\n",
    "\n",
    "\n",
    "def trend_model(thetas, t, device):\n",
    "    p = thetas.size()[-1]\n",
    "    assert p <= 4, 'thetas_dim is too big.'\n",
    "    T = torch.tensor([t ** i for i in range(p)]).float()\n",
    "    return thetas.mm(T.to(device))\n",
    "\n",
    "\n",
    "def linear_space(backcast_length, forecast_length):\n",
    "    ls = np.arange(-backcast_length, forecast_length, 1) / forecast_length\n",
    "    b_ls = ls[:backcast_length]\n",
    "    f_ls = ls[backcast_length:]\n",
    "    return b_ls, f_ls\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "\n",
    "    def __init__(self, units, thetas_dim, device, backcast_length=10, forecast_length=5, share_thetas=False,\n",
    "                 nb_harmonics=None):\n",
    "        super(Block, self).__init__()\n",
    "        self.units = units\n",
    "        self.thetas_dim = thetas_dim\n",
    "        self.backcast_length = backcast_length\n",
    "        self.forecast_length = forecast_length\n",
    "        self.share_thetas = share_thetas\n",
    "        self.fc1 = nn.Linear(backcast_length, units)\n",
    "        self.fc2 = nn.Linear(units, units)\n",
    "        self.fc3 = nn.Linear(units, units)\n",
    "        self.fc4 = nn.Linear(units, units)\n",
    "        self.device = device\n",
    "        self.backcast_linspace, self.forecast_linspace = linear_space(backcast_length, forecast_length)\n",
    "        if share_thetas:\n",
    "            self.theta_f_fc = self.theta_b_fc = nn.Linear(units, thetas_dim, bias=False)\n",
    "        else:\n",
    "            self.theta_b_fc = nn.Linear(units, thetas_dim, bias=False)\n",
    "            self.theta_f_fc = nn.Linear(units, thetas_dim, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = squeeze_last_dim(x)\n",
    "        x = F.relu(self.fc1(x.to(self.device)))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        return x\n",
    "\n",
    "    def __str__(self):\n",
    "        block_type = type(self).__name__\n",
    "        return f'{block_type}(units={self.units}, thetas_dim={self.thetas_dim}, ' \\\n",
    "               f'backcast_length={self.backcast_length}, forecast_length={self.forecast_length}, ' \\\n",
    "               f'share_thetas={self.share_thetas}) at @{id(self)}'\n",
    "\n",
    "\n",
    "class SeasonalityBlock(Block):\n",
    "\n",
    "    def __init__(self, units, thetas_dim, device, backcast_length=10, forecast_length=5, nb_harmonics=None):\n",
    "        if nb_harmonics:\n",
    "            super(SeasonalityBlock, self).__init__(units, nb_harmonics, device, backcast_length,\n",
    "                                                   forecast_length, share_thetas=True)\n",
    "        else:\n",
    "            super(SeasonalityBlock, self).__init__(units, forecast_length, device, backcast_length,\n",
    "                                                   forecast_length, share_thetas=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = super(SeasonalityBlock, self).forward(x)\n",
    "        backcast = seasonality_model(self.theta_b_fc(x), self.backcast_linspace, self.device)\n",
    "        forecast = seasonality_model(self.theta_f_fc(x), self.forecast_linspace, self.device)\n",
    "        return backcast, forecast\n",
    "\n",
    "\n",
    "class TrendBlock(Block):\n",
    "\n",
    "    def __init__(self, units, thetas_dim, device, backcast_length=10, forecast_length=5, nb_harmonics=None):\n",
    "        super(TrendBlock, self).__init__(units, thetas_dim, device, backcast_length,\n",
    "                                         forecast_length, share_thetas=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = super(TrendBlock, self).forward(x)\n",
    "        backcast = trend_model(self.theta_b_fc(x), self.backcast_linspace, self.device)\n",
    "        forecast = trend_model(self.theta_f_fc(x), self.forecast_linspace, self.device)\n",
    "        return backcast, forecast\n",
    "\n",
    "\n",
    "class GenericBlock(Block):\n",
    "\n",
    "    def __init__(self, units, thetas_dim, device, backcast_length=10, forecast_length=5, nb_harmonics=None):\n",
    "        super(GenericBlock, self).__init__(units, thetas_dim, device, backcast_length, forecast_length)\n",
    "\n",
    "        self.backcast_fc = nn.Linear(thetas_dim, backcast_length)\n",
    "        self.forecast_fc = nn.Linear(thetas_dim, forecast_length)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # no constraint for generic arch.\n",
    "        x = super(GenericBlock, self).forward(x)\n",
    "\n",
    "        theta_b = F.relu(self.theta_b_fc(x))\n",
    "        theta_f = F.relu(self.theta_f_fc(x))\n",
    "\n",
    "        backcast = self.backcast_fc(theta_b)  # generic. 3.3.\n",
    "        forecast = self.forecast_fc(theta_f)  # generic. 3.3.\n",
    "\n",
    "        return backcast, forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#hide\\n#Write\\ndf.to_csv(\\'example.csv\\', header = False, index = False)\\n#wite append\\ndf.to_csv(\\'example.csv\\', mode=\\'a\\', index=False, header=False)\\n\\nwith open(\"obj.pickle\", \"wb\") as f:\\n    pickle.dump(df, f)\\n\\n#read\\ndf = pd.read_csv(\\'example2.csv\\', header = False, index = True)\\n\\nwith open(\"obj.pickle\", \"rb\") as f:\\n    obj = pickle.load(f)\\n\\n#save list?\\nlistToStr = \\' \\'.join([str(elem) for elem in s])'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"#hide\n",
    "#Write\n",
    "df.to_csv('example.csv', header = False, index = False)\n",
    "#wite append\n",
    "df.to_csv('example.csv', mode='a', index=False, header=False)\n",
    "\n",
    "with open(\"obj.pickle\", \"wb\") as f:\n",
    "    pickle.dump(df, f)\n",
    "\n",
    "#read\n",
    "df = pd.read_csv('example2.csv', header = False, index = True)\n",
    "\n",
    "with open(\"obj.pickle\", \"rb\") as f:\n",
    "    obj = pickle.load(f)\n",
    "\n",
    "#save list?\n",
    "listToStr = ' '.join([str(elem) for elem in s])\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
